
# Project Title

MultiModel VQA ResNet RoBERTa



## Authors

- [@Haseeb-CS](https://github.com/Haseeb-CS)



# Hi, I'm Haseeb! ðŸ‘‹

Hello there! Welcome to my profile!

I am a results-driven AI Engineer currently advancing my expertise by pursuing a Master's in Artificial Intelligence at the University of Lincoln. I hold a first-class equivalent Bachelor's degree in Computer Science and have experience working with leading, US-based AI companies. My technical skill set is centered around Computer Vision, Machine Learning, Deep Learning, and Generative AI. My primary goal is to leverage this broad expertise to tackle challenging projects and drive impactful solutions across the AI landscape.
## ðŸ›  Skills


### Generative AI & LLMs
RAG Chatbots 


Llama Agents 

Multi-agentic chatbots 
Fine-tuning LLMs and open-source models 


Stable Diffusion 


Text-to-Image Generation 


Image-to-Image 

Prompt Engineering 
Generative AI 


Large Language Models 

Encoder-Decoder Architecture 

### Computer Vision
Image Recognition 

Object Detection (including YOLO) 


Object Segmentation 

Object Tracking 

Object Classification 

Face Recognition (including FaceNet) 
UK license plate recognition and validation 
Helmet detection on motorbikes 
### Machine Learning & Data Science
Machine Learning 




Deep Learning 
Sentiment Analysis 


Topic Modelling 

Predictive Modeling (using models like Random Forest) 
Bert/RoBert 

### Other Technical Skills
Automations 

Multi-Platform Integrations 

Microsoft Outlook plugin development 

Google Cloud 

ABAP Language 

Sources











Video

Deep Research

Canvas

Gemini can make mistakes, including about people, so double-check it. Your privacy and Gemini


## Features

- ### Multimodal Architecture: 
Seamlessly integrates a powerful Computer Vision model (ResNet-50) and a state-of-the-art Natural Language Processing model (RoBERTa) to understand both images and text simultaneously.

- ### Transfer Learning: 
Leverages pre-trained weights from established models, enabling high performance and efficient training on the specific Visual Question Answering task.

- ### End-to-End Pipeline: 
Provides a complete, self-contained workflow from data loading and preprocessing to model training, evaluation, and visualization of results.

- ### Comprehensive Evaluation Suite: 
Evaluates model performance using a wide range of metrics, including Accuracy, Precision, Recall, Confusion Matrix, ROC/AUC Curve, Precision-Recall Curve, and Mean Reciprocal Rank (MRR).

- ### Modular and Readable Code: 
Written with a clean, object-oriented structure that makes the code easy to understand, modify, and extend for future experiments.


## Project Description

In a world saturated with visual data, one of the great frontiers for artificial intelligence is not just to see images or read text, but to understand them together, just as humans do. How can we teach a machine to look at a photograph and answer a simple question about it? This fundamental challenge lies at the heart of multimodal AI and is the central problem this project aims to solve.

The goal here is to build a robust model for Visual Question Answering (VQA). The reason this is so important is that it represents a true test of a machine's conceptual understanding. To succeed, the AI cannot simply recognize objects; it must comprehend their relationships, attributes, and the context provided by the question.

This project tackles this challenge by taking a strategic and powerful approach. Instead of building a massive model from scratch, it stands on the shoulders of giants, employing a "dream team" of pre-trained deep learning models:

- ResNet-50, a master of computer vision, acts as the model's "eyes" to analyze and encode the image into a rich set of features.
- RoBERTa, a powerhouse of natural language processing, serves as the "ears" to deconstruct and understand the nuances of the question.
The core value of this project is in demonstrating how to elegantly fuse these two distinct modalities into a single, cohesive system. The model learns to combine the visual evidence with the textual query to make a final, informed decision. By framing the task as a classification problemâ€”determining if a question-answer pair is a "Match" or "No Match" for the imageâ€”we create an efficient and effective solution.